{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import path\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import SerpAPIWrapper\n",
    "from langchain.agents.tools import Tool\n",
    "from langchain import LLMMathChain\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True, dotenv_path='../../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME=\"gpt-4-0613\"\n",
    "llm = ChatOpenAI(temperature=0, model=MODEL_NAME)\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "tools: list[Tool] = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME=\"gpt-3.5-turbo-0613\"\n",
    "MODEL_NAME=\"gpt-4-0613\"\n",
    "llm = ChatOpenAI(temperature=0, model=MODEL_NAME)\n",
    "# model = ChatOpenAI(temperature=0)\n",
    "planner = load_chat_planner(llm)\n",
    "executor = load_agent_executor(llm, tools, verbose=True)\n",
    "agent = PlanAndExecute(planner=planner, executor=executor, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this so we can see exactly what's going on under the hood\n",
    "import langchain\n",
    "\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 2:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\",\n",
      "  \"stop\": [\n",
      "    \"<END_OF_PLAN>\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 2:chain:LLMChain > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Let's first understand the problem and devise a plan to solve the problem. Please output the plan starting with the header 'Plan:' and then followed by a numbered list of steps. Please make the plan the minimum number of steps required to accurately complete the task. If the task is a question, the final step should almost always be 'Given the above steps taken, please respond to the users original question'. At the end of your plan, say '<END_OF_PLAN>'\\nHuman: Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 2:chain:LLMChain > 3:llm:ChatOpenAI] [4.19s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Plan:\\n1. Research the current girlfriend of Leonardo DiCaprio.\\n2. Find out her current age.\\n3. Calculate her age raised to the 0.43 power.\\n4. Given the above steps taken, please respond to the users original question.\\n\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Plan:\\n1. Research the current girlfriend of Leonardo DiCaprio.\\n2. Find out her current age.\\n3. Calculate her age raised to the 0.43 power.\\n4. Given the above steps taken, please respond to the users original question.\\n\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 128,\n",
      "      \"completion_tokens\": 52,\n",
      "      \"total_tokens\": 180\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-0613\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 2:chain:LLMChain] [4.19s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Plan:\\n1. Research the current girlfriend of Leonardo DiCaprio.\\n2. Find out her current age.\\n3. Calculate her age raised to the 0.43 power.\\n4. Given the above steps taken, please respond to the users original question.\\n\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 4:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 4:chain:AgentExecutor > 5:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 4:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nSearch: useful for when you need to answer questions about current events, args: {{'tool_input': {{'type': 'string'}}}}\\nCalculator: useful for when you need to answer questions about math, args: {{'tool_input': {{'type': 'string'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" or Search, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:\\nHuman: Previous steps: steps=[]\\n\\nCurrent objective: value='Research the current girlfriend of Leonardo DiCaprio.'\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 4:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI] [4.51s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Thought: I need to find out who Leonardo DiCaprio is currently dating. I will use the search tool to find this information.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Search\\\",\\n  \\\"action_input\\\": \\\"Leonardo DiCaprio current girlfriend\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Thought: I need to find out who Leonardo DiCaprio is currently dating. I will use the search tool to find this information.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Search\\\",\\n  \\\"action_input\\\": \\\"Leonardo DiCaprio current girlfriend\\\"\\n}\\n```\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 311,\n",
      "      \"completion_tokens\": 55,\n",
      "      \"total_tokens\": 366\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-0613\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 4:chain:AgentExecutor > 5:chain:LLMChain] [4.51s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Thought: I need to find out who Leonardo DiCaprio is currently dating. I will use the search tool to find this information.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Search\\\",\\n  \\\"action_input\\\": \\\"Leonardo DiCaprio current girlfriend\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 4:chain:AgentExecutor > 7:tool:Search] Entering Tool run with input:\n",
      "\u001b[0m\"Leonardo DiCaprio current girlfriend\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 4:chain:AgentExecutor > 7:tool:Search] [2.40s] Exiting Tool run with output:\n",
      "\u001b[0m\"Leonardo DiCaprio has been linked with 19-year-old model Eden Polani, continuing the rumour that he doesn't date any women over the age of ...\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 4:chain:AgentExecutor > 8:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 4:chain:AgentExecutor > 8:chain:LLMChain > 9:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nSearch: useful for when you need to answer questions about current events, args: {{'tool_input': {{'type': 'string'}}}}\\nCalculator: useful for when you need to answer questions about math, args: {{'tool_input': {{'type': 'string'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" or Search, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:\\nHuman: Previous steps: steps=[]\\n\\nCurrent objective: value='Research the current girlfriend of Leonardo DiCaprio.'\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nThought: I need to find out who Leonardo DiCaprio is currently dating. I will use the search tool to find this information.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Search\\\",\\n  \\\"action_input\\\": \\\"Leonardo DiCaprio current girlfriend\\\"\\n}\\n```\\nObservation: Leonardo DiCaprio has been linked with 19-year-old model Eden Polani, continuing the rumour that he doesn't date any women over the age of ...\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 4:chain:AgentExecutor > 8:chain:LLMChain > 9:llm:ChatOpenAI] [6.11s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The search results indicate that Leonardo DiCaprio is currently linked with a 19-year-old model named Eden Polani. However, this information might be based on rumors, so it's important to note that. I will provide this information as the answer. \\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Leonardo DiCaprio is currently linked with a 19-year-old model named Eden Polani. Please note that this information might be based on rumors.\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The search results indicate that Leonardo DiCaprio is currently linked with a 19-year-old model named Eden Polani. However, this information might be based on rumors, so it's important to note that. I will provide this information as the answer. \\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Leonardo DiCaprio is currently linked with a 19-year-old model named Eden Polani. Please note that this information might be based on rumors.\\\"\\n}\\n```\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 430,\n",
      "      \"completion_tokens\": 104,\n",
      "      \"total_tokens\": 534\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-0613\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 4:chain:AgentExecutor > 8:chain:LLMChain] [6.11s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"The search results indicate that Leonardo DiCaprio is currently linked with a 19-year-old model named Eden Polani. However, this information might be based on rumors, so it's important to note that. I will provide this information as the answer. \\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Leonardo DiCaprio is currently linked with a 19-year-old model named Eden Polani. Please note that this information might be based on rumors.\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 4:chain:AgentExecutor] [13.02s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Leonardo DiCaprio is currently linked with a 19-year-old model named Eden Polani. Please note that this information might be based on rumors.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 10:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 10:chain:AgentExecutor > 11:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 10:chain:AgentExecutor > 11:chain:LLMChain > 12:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nSearch: useful for when you need to answer questions about current events, args: {{'tool_input': {{'type': 'string'}}}}\\nCalculator: useful for when you need to answer questions about math, args: {{'tool_input': {{'type': 'string'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" or Search, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:\\nHuman: Previous steps: steps=[(Step(value='Research the current girlfriend of Leonardo DiCaprio.'), StepResponse(response='Leonardo DiCaprio is currently linked with a 19-year-old model named Eden Polani. Please note that this information might be based on rumors.'))]\\n\\nCurrent objective: value='Find out her current age.'\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 10:chain:AgentExecutor > 11:chain:LLMChain > 12:llm:ChatOpenAI] [3.35s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Thought: I need to find out the current age of Eden Polani, who is reportedly Leonardo DiCaprio's girlfriend. I will use the search tool to find this information.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Search\\\",\\n  \\\"action_input\\\": \\\"Eden Polani current age\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Thought: I need to find out the current age of Eden Polani, who is reportedly Leonardo DiCaprio's girlfriend. I will use the search tool to find this information.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Search\\\",\\n  \\\"action_input\\\": \\\"Eden Polani current age\\\"\\n}\\n```\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 358,\n",
      "      \"completion_tokens\": 63,\n",
      "      \"total_tokens\": 421\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-0613\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 10:chain:AgentExecutor > 11:chain:LLMChain] [3.35s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Thought: I need to find out the current age of Eden Polani, who is reportedly Leonardo DiCaprio's girlfriend. I will use the search tool to find this information.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Search\\\",\\n  \\\"action_input\\\": \\\"Eden Polani current age\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 10:chain:AgentExecutor > 13:tool:Search] Entering Tool run with input:\n",
      "\u001b[0m\"Eden Polani current age\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 10:chain:AgentExecutor > 13:tool:Search] [1.14s] Exiting Tool run with output:\n",
      "\u001b[0m\"19 years old\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 10:chain:AgentExecutor > 14:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 10:chain:AgentExecutor > 14:chain:LLMChain > 15:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nSearch: useful for when you need to answer questions about current events, args: {{'tool_input': {{'type': 'string'}}}}\\nCalculator: useful for when you need to answer questions about math, args: {{'tool_input': {{'type': 'string'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" or Search, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:\\nHuman: Previous steps: steps=[(Step(value='Research the current girlfriend of Leonardo DiCaprio.'), StepResponse(response='Leonardo DiCaprio is currently linked with a 19-year-old model named Eden Polani. Please note that this information might be based on rumors.'))]\\n\\nCurrent objective: value='Find out her current age.'\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nThought: I need to find out the current age of Eden Polani, who is reportedly Leonardo DiCaprio's girlfriend. I will use the search tool to find this information.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Search\\\",\\n  \\\"action_input\\\": \\\"Eden Polani current age\\\"\\n}\\n```\\nObservation: 19 years old\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 10:chain:AgentExecutor > 14:chain:LLMChain > 15:llm:ChatOpenAI] [4.48s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The search tool has provided the information that Eden Polani is currently 19 years old. This information matches the previous information provided about her. I can now provide this as the final answer. \\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Eden Polani, who is reportedly Leonardo DiCaprio's girlfriend, is currently 19 years old.\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The search tool has provided the information that Eden Polani is currently 19 years old. This information matches the previous information provided about her. I can now provide this as the final answer. \\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Eden Polani, who is reportedly Leonardo DiCaprio's girlfriend, is currently 19 years old.\\\"\\n}\\n```\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 457,\n",
      "      \"completion_tokens\": 82,\n",
      "      \"total_tokens\": 539\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-0613\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 10:chain:AgentExecutor > 14:chain:LLMChain] [4.48s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"The search tool has provided the information that Eden Polani is currently 19 years old. This information matches the previous information provided about her. I can now provide this as the final answer. \\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Eden Polani, who is reportedly Leonardo DiCaprio's girlfriend, is currently 19 years old.\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 10:chain:AgentExecutor] [8.98s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Eden Polani, who is reportedly Leonardo DiCaprio's girlfriend, is currently 19 years old.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 17:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 17:chain:LLMChain > 18:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nSearch: useful for when you need to answer questions about current events, args: {{'tool_input': {{'type': 'string'}}}}\\nCalculator: useful for when you need to answer questions about math, args: {{'tool_input': {{'type': 'string'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" or Search, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:\\nHuman: Previous steps: steps=[(Step(value='Research the current girlfriend of Leonardo DiCaprio.'), StepResponse(response='Leonardo DiCaprio is currently linked with a 19-year-old model named Eden Polani. Please note that this information might be based on rumors.')), (Step(value='Find out her current age.'), StepResponse(response=\\\"Eden Polani, who is reportedly Leonardo DiCaprio's girlfriend, is currently 19 years old.\\\"))]\\n\\nCurrent objective: value='Calculate her age raised to the 0.43 power.'\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 17:chain:LLMChain > 18:llm:ChatOpenAI] [3.06s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Thought: The current objective is to calculate the age of Eden Polani raised to the power of 0.43. Since this is a mathematical operation, I will use the Calculator tool. \\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Calculator\\\",\\n  \\\"action_input\\\": \\\"19^0.43\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Thought: The current objective is to calculate the age of Eden Polani raised to the power of 0.43. Since this is a mathematical operation, I will use the Calculator tool. \\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Calculator\\\",\\n  \\\"action_input\\\": \\\"19^0.43\\\"\\n}\\n```\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 402,\n",
      "      \"completion_tokens\": 65,\n",
      "      \"total_tokens\": 467\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-0613\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 17:chain:LLMChain] [3.06s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Thought: The current objective is to calculate the age of Eden Polani raised to the power of 0.43. Since this is a mathematical operation, I will use the Calculator tool. \\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Calculator\\\",\\n  \\\"action_input\\\": \\\"19^0.43\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 19:tool:Calculator] Entering Tool run with input:\n",
      "\u001b[0m\"19^0.43\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 19:tool:Calculator > 20:chain:LLMMathChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"19^0.43\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 19:tool:Calculator > 20:chain:LLMMathChain > 21:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"19^0.43\",\n",
      "  \"stop\": [\n",
      "    \"```output\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 19:tool:Calculator > 20:chain:LLMMathChain > 21:chain:LLMChain > 22:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Translate a math problem into a expression that can be executed using Python's numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${Question with math problem.}\\n```text\\n${single line mathematical expression that solves the problem}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${Output of running the code}\\n```\\nAnswer: ${Answer}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\\\"37593 * 67\\\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\\\"37593**(1/5)\\\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: 19^0.43\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 19:tool:Calculator > 20:chain:LLMMathChain > 21:chain:LLMChain > 22:llm:ChatOpenAI] [1.56s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```text\\n19**0.43\\n```\\n...numexpr.evaluate(\\\"19**0.43\\\")...\\n\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```text\\n19**0.43\\n```\\n...numexpr.evaluate(\\\"19**0.43\\\")...\\n\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 205,\n",
      "      \"completion_tokens\": 23,\n",
      "      \"total_tokens\": 228\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-0613\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 19:tool:Calculator > 20:chain:LLMMathChain > 21:chain:LLMChain] [1.56s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```text\\n19**0.43\\n```\\n...numexpr.evaluate(\\\"19**0.43\\\")...\\n\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 19:tool:Calculator > 20:chain:LLMMathChain] [1.56s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"answer\": \"Answer: 3.547023357958959\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 19:tool:Calculator] [1.56s] Exiting Tool run with output:\n",
      "\u001b[0m\"Answer: 3.547023357958959\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 23:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 23:chain:LLMChain > 24:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nSearch: useful for when you need to answer questions about current events, args: {{'tool_input': {{'type': 'string'}}}}\\nCalculator: useful for when you need to answer questions about math, args: {{'tool_input': {{'type': 'string'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" or Search, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:\\nHuman: Previous steps: steps=[(Step(value='Research the current girlfriend of Leonardo DiCaprio.'), StepResponse(response='Leonardo DiCaprio is currently linked with a 19-year-old model named Eden Polani. Please note that this information might be based on rumors.')), (Step(value='Find out her current age.'), StepResponse(response=\\\"Eden Polani, who is reportedly Leonardo DiCaprio's girlfriend, is currently 19 years old.\\\"))]\\n\\nCurrent objective: value='Calculate her age raised to the 0.43 power.'\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nThought: The current objective is to calculate the age of Eden Polani raised to the power of 0.43. Since this is a mathematical operation, I will use the Calculator tool. \\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Calculator\\\",\\n  \\\"action_input\\\": \\\"19^0.43\\\"\\n}\\n```\\nObservation: Answer: 3.547023357958959\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 23:chain:LLMChain > 24:llm:ChatOpenAI] [4.81s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The calculator tool has provided the result of 19 raised to the power of 0.43, which is approximately 3.55. I will now provide this answer to the user. \\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"The age of Eden Polani raised to the power of 0.43 is approximately 3.55.\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The calculator tool has provided the result of 19 raised to the power of 0.43, which is approximately 3.55. I will now provide this answer to the user. \\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"The age of Eden Polani raised to the power of 0.43 is approximately 3.55.\\\"\\n}\\n```\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 509,\n",
      "      \"completion_tokens\": 82,\n",
      "      \"total_tokens\": 591\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-0613\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor > 23:chain:LLMChain] [4.81s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"The calculator tool has provided the result of 19 raised to the power of 0.43, which is approximately 3.55. I will now provide this answer to the user. \\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"The age of Eden Polani raised to the power of 0.43 is approximately 3.55.\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 16:chain:AgentExecutor] [9.44s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The age of Eden Polani raised to the power of 0.43 is approximately 3.55.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 25:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 25:chain:AgentExecutor > 26:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 25:chain:AgentExecutor > 26:chain:LLMChain > 27:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nSearch: useful for when you need to answer questions about current events, args: {{'tool_input': {{'type': 'string'}}}}\\nCalculator: useful for when you need to answer questions about math, args: {{'tool_input': {{'type': 'string'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \\\"action\\\" values: \\\"Final Answer\\\" or Search, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Final response to human\\\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:\\nHuman: Previous steps: steps=[(Step(value='Research the current girlfriend of Leonardo DiCaprio.'), StepResponse(response='Leonardo DiCaprio is currently linked with a 19-year-old model named Eden Polani. Please note that this information might be based on rumors.')), (Step(value='Find out her current age.'), StepResponse(response=\\\"Eden Polani, who is reportedly Leonardo DiCaprio's girlfriend, is currently 19 years old.\\\")), (Step(value='Calculate her age raised to the 0.43 power.'), StepResponse(response='The age of Eden Polani raised to the power of 0.43 is approximately 3.55.'))]\\n\\nCurrent objective: value='Given the above steps taken, please respond to the users original question.\\\\n'\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 25:chain:AgentExecutor > 26:chain:LLMChain > 27:llm:ChatOpenAI] [6.16s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Thought: The user's original question seems to be about the current girlfriend of Leonardo DiCaprio and a specific calculation related to her age. The steps taken have provided the necessary information to answer this question. \\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Leonardo DiCaprio's current girlfriend is reportedly a 19-year-old model named Eden Polani. When her age is raised to the power of 0.43, the result is approximately 3.55.\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Thought: The user's original question seems to be about the current girlfriend of Leonardo DiCaprio and a specific calculation related to her age. The steps taken have provided the necessary information to answer this question. \\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Leonardo DiCaprio's current girlfriend is reportedly a 19-year-old model named Eden Polani. When her age is raised to the power of 0.43, the result is approximately 3.55.\\\"\\n}\\n```\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 450,\n",
      "      \"completion_tokens\": 107,\n",
      "      \"total_tokens\": 557\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-0613\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 25:chain:AgentExecutor > 26:chain:LLMChain] [6.16s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Thought: The user's original question seems to be about the current girlfriend of Leonardo DiCaprio and a specific calculation related to her age. The steps taken have provided the necessary information to answer this question. \\n\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Final Answer\\\",\\n  \\\"action_input\\\": \\\"Leonardo DiCaprio's current girlfriend is reportedly a 19-year-old model named Eden Polani. When her age is raised to the power of 0.43, the result is approximately 3.55.\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute > 25:chain:AgentExecutor] [6.16s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Leonardo DiCaprio's current girlfriend is reportedly a 19-year-old model named Eden Polani. When her age is raised to the power of 0.43, the result is approximately 3.55.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:PlanAndExecute] [41.79s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Leonardo DiCaprio's current girlfriend is reportedly a 19-year-old model named Eden Polani. When her age is raised to the power of 0.43, the result is approximately 3.55.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.output_parser import OutputParserException\n",
    "\n",
    "try:\n",
    "  agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\")\n",
    "except OutputParserException as e:\n",
    "  # todo: try to have OpenAI fix this error.\n",
    "  # call debugger agent.\n",
    "  print(e)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Leonardo DiCaprio's current girlfriend is reportedly a 19-year-old model named Eden Polani. When her age is raised to the power of 0.43, the result is approximately 3.55.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
