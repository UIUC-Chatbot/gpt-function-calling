{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING\"] = \"true\" # If you want to trace the execution of the program, set to \"true\"\n",
    "\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, load_tools\n",
    "\n",
    "from langchain.agents.agent_toolkits import PlayWrightBrowserToolkit\n",
    "from langchain.tools.playwright.utils import (\n",
    "    create_async_playwright_browser,\n",
    "    create_sync_playwright_browser, # A synchronous browser is available, though it isn't compatible with jupyter.\n",
    ")\n",
    "\n",
    "# This import is required only for jupyter notebooks, since they have their own eventloop\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input() -> str:\n",
    "  \"\"\"Placeholder for Slack input from user.\"\"\"\n",
    "  print(\"Insert your text. Enter 'q' or press Ctrl-D (or Ctrl-Z on Windows) to end.\")\n",
    "  contents = []\n",
    "  while True:\n",
    "    try:\n",
    "      line = input()\n",
    "    except EOFError:\n",
    "      break\n",
    "    if line == \"q\":\n",
    "      break\n",
    "    contents.append(line)\n",
    "  return \"\\n\".join(contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEMORY \n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "chat_history = MessagesPlaceholder(variable_name=\"chat_history\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM \n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4-0613\", max_retries=3, request_timeout=60 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOLS\n",
    "async_browser = create_async_playwright_browser()\n",
    "browser_toolkit = PlayWrightBrowserToolkit.from_browser(async_browser=async_browser)\n",
    "tools = browser_toolkit.get_tools()\n",
    "tools\n",
    "\n",
    "human_tools = load_tools(\n",
    "    [\"human\"],\n",
    "    llm=llm,\n",
    "    input_func=get_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ClickTool(name='click_element', description='Click on an element with the given CSS selector', args_schema=<class 'langchain.tools.playwright.click.ClickToolInput'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>, visible_only=True, playwright_strict=False, playwright_timeout=1000),\n",
       " NavigateTool(name='navigate_browser', description='Navigate a browser to the specified URL', args_schema=<class 'langchain.tools.playwright.navigate.NavigateToolInput'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>),\n",
       " NavigateBackTool(name='previous_webpage', description='Navigate back to the previous page in the browser history', args_schema=<class 'pydantic.main.BaseModel'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>),\n",
       " ExtractTextTool(name='extract_text', description='Extract all the text on the current webpage', args_schema=<class 'pydantic.main.BaseModel'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>),\n",
       " ExtractHyperlinksTool(name='extract_hyperlinks', description='Extract all hyperlinks on the current webpage', args_schema=<class 'langchain.tools.playwright.extract_hyperlinks.ExtractHyperlinksToolInput'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>),\n",
       " GetElementsTool(name='get_elements', description='Retrieve elements in the current web page matching the given CSS selector', args_schema=<class 'langchain.tools.playwright.get_elements.GetElementsToolInput'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>),\n",
       " CurrentWebPageTool(name='current_webpage', description='Returns the URL of the current page', args_schema=<class 'pydantic.main.BaseModel'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>),\n",
       " HumanInputRun(name='human', description='You can ask a human for guidance when you think you got stuck or you are not sure what to do next. The input should be a question for the human.', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, prompt_func=<function _print_func at 0x11b4a35b0>, input_func=<function get_input at 0x13f2eb640>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = tools + human_tools\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(\n",
    "  tools, \n",
    "  llm, \n",
    "  agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, \n",
    "  verbose=True,\n",
    "  memory=memory, \n",
    "  agent_kwargs = {\n",
    "    \"memory_prompts\": [chat_history],\n",
    "    \"input_variables\": [\"input\", \"agent_scratchpad\", \"chat_history\"]\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to load default session, using empty session: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sessions?name=default (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x13f360a90>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to persist run: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /chain-runs (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x13f9b8730>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: The assistant cannot physically interact with a keyboard or a webpage. It can only perform actions such as navigating to a URL, clicking on elements, extracting text, and so on. I should inform the user about this limitation.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"I'm sorry, but as an AI, I don't have the ability to physically interact with a keyboard or a webpage. I can perform actions such as navigating to a URL, clicking on elements, extracting text, and so on. However, I can guide you through the process if you'd like.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I'm sorry, but as an AI, I don't have the ability to physically interact with a keyboard or a webpage. I can perform actions such as navigating to a URL, clicking on elements, extracting text, and so on. However, I can guide you through the process if you'd like.\n"
     ]
    }
   ],
   "source": [
    "# asycn and sync together is tough...\n",
    "\n",
    "response = await agent_chain.arun(input=\"Browse to https://lumetta.web.engr.illinois.edu/120-binary/120-binary.html and complete the first challenge using the keyboard to enter information, please.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to load default session, using empty session: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sessions?name=default (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x164d5b520>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Before I can browse and summarize the text from the blog, I need to know what the user is interested in learning about on Langchain. I will ask the user for this information.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"human\",\n",
      "  \"action_input\": {\n",
      "    \"query\": \"What specific topics are you interested in learning about on Langchain?\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "What specific topics are you interested in learning about on Langchain?\n",
      "Insert your text. Enter 'q' or press Ctrl-D (or Ctrl-Z on Windows) to end.\n",
      "\n",
      "Observation: \u001b[31;1m\u001b[1;3mAgents and Chains\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe user is interested in learning about \"Agents\" and \"Chains\" on Langchain. Now, I will navigate to the blog.langchain.dev to find relevant information.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"navigate_browser\",\n",
      "  \"action_input\": {\n",
      "    \"url\": \"https://blog.langchain.dev\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mNavigating to https://blog.langchain.dev returned status code 200\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe website has loaded successfully. Now, I will extract all the text from the webpage to find information relevant to \"Agents\" and \"Chains\".\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"extract_text\",\n",
      "  \"action_input\": {}\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mLangChain LangChain Home About GitHub Docs Sign in Subscribe LangChain The official LangChain blog. RealChar x LangSmith: Using Open Source tools to create an AI companion Editor’s Note: This blog post was written in collaboration with RealChar, an early LangSmith BETA user. They moved fast and created something really, really sophisticated and really, really fun to use–all with open source tools.\n",
      "\n",
      "We're also very excited about AI characters and companions internally, which is part Jul 24, 2023 3 min read Featured Announcing LangSmith, a unified platform for debugging, testing, evaluating, and monitoring your LLM applications LangChain exists to make it as easy as possible to develop LLM-powered applications.\n",
      "\n",
      "We started with an open-source Python package when the main blocker for building LLM-powered applications was getting a simple prototype working. We remember seeing Nat Friedman tweet in late 2022 that there was “not enough tinkering happening. Jul 18, 2023 8 min read Code Interpreter API Editor's Note: This is another installation of our guest blog posts highlighting interesting and novel use cases. This blog is written by Shroominic who built an open source implementation of the ChatGPT Code Interpreter.\n",
      "\n",
      "Important Links:\n",
      "\n",
      " * GitHub Repo\n",
      "\n",
      "In the world of open-source software, there are always exciting developments. Today, Jul 16, 2023 5 min read Analyzing User Interactions with LLMs to Improve our Documentation Introduction\n",
      "\n",
      "We're strongly committed to consistently enhancing our documentation and its navigability. Using Mendable, a AI-enabled chat application, users can search our documentation using keywords or questions. Over time, Mendable has collected a large dataset of questions that highlights areas for documentation improvement.\n",
      "\n",
      "\n",
      "Challenge\n",
      "\n",
      "Distilling common themes from tens of Jul 13, 2023 3 min read LangChain x Context: Building Better Chat Products With User Analytics Today we’re announcing a Langchain integration for Context. This integration allows builders of Langchain chat products to receive user analytics with a one line plugin.\n",
      "\n",
      "Building compelling chat products is hard. Developers need a deep understanding of user behaviour and user goals to iteratively improve their products. Common questions Jul 12, 2023 2 min read Neon x LangChain: HNSW in Postgres with pg_embedding Editor’s Note: This blog post was written in collaboration with the Neon team (Raouf Chebri in particular). The vectorstore space is on fire, and we’re excited to highlight new implementations and options. We’re also really excited by the detailed analysis done here, bringing some solid stats and Jul 12, 2023 4 min read LangChain 🤝 Streamlit The initial integration of Streamlit with LangChain and our future plans. Jul 11, 2023 2 min read 🎉 Prem Challenge🎉 We're excited to announce a challenge hosted by Prem in collaboration with LangChain.\n",
      "\n",
      "At LangChain we try to make it easy as possible to experiment with as many different models as possible. That includes the incredible number of emerging open source models. We've made efforts to make our framework as Jun 26, 2023 6 min read LangChain <> MongoDB Atlas Today we’re announcing LangChain’s integration with MongoDB Atlas, adding support for one of the most popular developer data platforms in the world. This is an integration so anticipated that a few developers added the integration before we were ready to announce it :)\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "One of the key components Jun 22, 2023 3 min read Data-Driven Characters Data-driven-characters is a repo for creating, debugging, and interacting your own chatbots conditioned on your own story corpora. Jun 19, 2023 11 min read LangChain + Vectara: better together Introduction\n",
      "\n",
      "One of the main use cases of LangChain is connecting LLMs to user data, allowing users to build personalized LLM applications. A key part of this is retrieval - fetching relevant documents based on user queries.\n",
      "\n",
      "Today we’re happy to announce the integration of Vectara into LangChain to Jun 6, 2023 4 min read GPTeam: A multi-agent simulation Editor's Note: This is another edition in our series of guest posts highlighting novel applications of LangChain. After the Generative Agents paper was released, there was a flurry of open source projects rushing to incorporate some of the key ideas. GPTeam was one of the most impressive ones we saw, Jun 5, 2023 11 min read Going Beyond Chatbots: How to Make GPT-4 Output Structured Data Using LangChain By Jacob Lee\n",
      "\n",
      "Over the past few months, I had the opportunity to do some cool exploratory work for a client that integrated LLMs like GPT-4 and Claude into their internal workflow, rather than exposing them through a chat interface. The general idea was to take some input data, analyze May 21, 2023 4 min read Auto-Evaluation of Anthropic 100k Context Window Lance Martin\n",
      "\n",
      "\n",
      "Retrieval Architectures\n",
      "\n",
      "LLM question answering (Q+A) typically involves retrieval of documents relevant to the question followed by synthesis of the retrieved chunks into an answer by an LLM.  In practice, the retrieval step is necessary because the LLM context window is limited relative to the size of May 16, 2023 3 min read Rebuff: Detecting Prompt Injection Attacks [Editor's Note]: we're excited to highlight a guest blog by Willem Pienaar. As more and more LangChains make their way into production, we're getting an increased amount of questions about the security and privacy of these systems. We did a webinar on this topic a few weeks ago, and the May 14, 2023 4 min read Plan-and-Execute Agents TL;DR: We’re introducing a new type of agent executor, which we’re calling “Plan-and-Execute”. This is to contrast against the previous types of agent we supported, which we’re calling “Action” agents. Plan-and-Execute agents are heavily inspired by BabyAGI and the recent Plan-and-Solve paper. We think Plan-and-Execute is May 10, 2023 4 min read Feature Stores and LLMs Editor's note: big thank you to Willem Pienaar (Feast), Mike Del Balso (Tecton), and Simba Khadder (FeatureForm) for their comments and help on this post.\n",
      "\n",
      "LLMs represent a new paradigm of AI. There is a big open question of how many of the tools and services that were useful for May 9, 2023 5 min read Structured Tools TL;DR: we're introducing a new abstraction to allow for usage of more complex tools. While previous tools took in a single string input, new tools can take in an arbitrary number of inputs of arbitrary types. We are also introducing a new agent class that works well with these May 2, 2023 6 min read Auto-Evaluator Opportunities Editor's Note: this is a guest blog post by Lance Martin.\n",
      "\n",
      "\n",
      "TL;DR\n",
      "\n",
      "We recently open-sourced an auto-evaluator tool for grading LLM question-answer chains. We are now releasing an open source, free to use hosted app and API to expand usability. Below we discuss a few opportunities to further improve May 1, 2023 5 min read Callbacks Improvements TL;DR: We're announcing improvements to our callbacks system, which powers logging, tracing, streaming output, and some awesome third-party integrations. This will better support concurrent runs with independent callbacks, tracing of deeply nested trees of LangChain components, and callback handlers scoped to a single request (which is super useful for May 1, 2023 3 min read Unleashing the power of AI Collaboration with Parallelized LLM Agent Actor Trees Editor's note: the following is a guest blog post from Cyrus at Shaman AI. We use guest blog posts to highlight interesting and novel applciations, and this is certainly that. There's been a lot of talk about agents recently, but most have been discussions around a single agent. If multiple Apr 28, 2023 4 min read Gradio & LLM Agents Editor's note: this is a guest blog post from Freddy Boulton, a software engineer at Gradio. We're excited to share this post because it brings a large number of exciting new tools into the ecosystem. Agents are largely defined by the tools they have, so to be able to equip Apr 23, 2023 4 min read RecAlign - The smart content filter for social media feed [Editor's Note] This is a guest post by Tian Jin. We are highlighting this application as we think it is a novel use case. Specifically, we think recommendation systems are incredibly impactful in our everyday lives and there has not been a ton of discourse on how LLMs will impact Apr 22, 2023 3 min read Improving Document Retrieval with Contextual Compression Note: This post assumes some familiarity with LangChain and is moderately technical.\n",
      "\n",
      "💡 TL;DR: We’ve introduced a new abstraction and a new document Retriever to facilitate the post-processing of retrieved documents. Specifically, the new abstraction makes it easy to take a set of retrieved documents and extract from them Apr 20, 2023 3 min read Autonomous Agents & Agent Simulations Over the past two weeks, there has been a massive increase in using LLMs in an agentic manner. Specifically, projects like AutoGPT, BabyAGI, CAMEL, and Generative Agents have popped up. The LangChain community has now implemented some parts of all of those projects in the LangChain framework. While researching and Apr 18, 2023 7 min read Page 1 of 3 Older Posts → LangChain © 2023 Sign up Powered by Ghost\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe extracted text contains several mentions of \"agents\", but no explicit mentions of \"chains\". I will need to summarize the relevant information about \"agents\" and also look for implicit references to \"chains\" in the context of Langchain.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"get_elements\",\n",
      "  \"action_input\": {\n",
      "    \"selector\": \"p\",\n",
      "    \"attributes\": [\"innerText\"]\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m[{\"innerText\": \"The official LangChain blog.\"}]\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to persist run: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /chain-runs (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x16636f490>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe extracted paragraph does not contain any relevant information about \"Agents\" or \"Chains\". I will now summarize the relevant information about \"Agents\" from the extracted text and look for implicit references to \"Chains\".\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"LangChain has been implementing a new type of agent executor called 'Plan-and-Execute', contrasting against the previous types of agents, which are referred to as 'Action' agents. These Plan-and-Execute agents are heavily inspired by BabyAGI and the recent Plan-and-Solve paper. There's also mention of a multi-agent simulation called GPTeam, which was one of the most impressive applications seen after the Generative Agents paper was released. However, there were no explicit mentions of 'Chains' in the context of Langchain in the extracted text.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "LangChain has been implementing a new type of agent executor called 'Plan-and-Execute', contrasting against the previous types of agents, which are referred to as 'Action' agents. These Plan-and-Execute agents are heavily inspired by BabyAGI and the recent Plan-and-Solve paper. There's also mention of a multi-agent simulation called GPTeam, which was one of the most impressive applications seen after the Generative Agents paper was released. However, there were no explicit mentions of 'Chains' in the context of Langchain in the extracted text.\n"
     ]
    }
   ],
   "source": [
    "# asycn and sync together is tough...\n",
    "\n",
    "response = await agent_chain.arun(input=\"Ask the user what they're interested in learning about on Langchain, then Browse to blog.langchain.dev and summarize the text especially whatever is relevant to the user, please.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain has been implementing a new type of agent executor called 'Plan-and-Execute', contrasting against the previous types of agents, which are referred to as 'Action' agents. These Plan-and-Execute agents are heavily inspired by BabyAGI and the recent Plan-and-Solve paper. There's also mention of a multi-agent simulation called GPTeam, which was one of the most impressive applications seen after the Generative Agents paper was released. However, there were no explicit mentions of 'Chains' in the context of Langchain in the extracted text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "The LangChain blog contains several posts relevant to your interests. The post titled 'Plan-and-Execute Agents' introduces a new type of agent executor called 'Plan-and-Execute', which contrasts against the previous types of agents, referred to as 'Action' agents. In the post titled 'Structured Tools', a new abstraction is introduced to allow for the usage of more complex tools. The post 'GPTeam: A multi-agent simulation' highlights novel applications of LangChain, indicating a strong interest in agent-based applications. The post 'Unleashing the power of AI Collaboration with Parallelized LLM Agent Actor Trees' discusses the potential of multiple agents working in parallel. This suggests that there is a lot of ongoing research and development in the area of agents and structured tools on LangChain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = await agent_chain.arun(input=\"Browse to blog.langchain.dev and summarize the text, please.\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------------------\n",
    "\n",
    "### Quick tool definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='get_huggingface_models' description='get_huggingface_models(path: Optional[str] = None, query_params: Optional[dict] = None) -> dict - Tool that calls GET on <https://huggingface.co/models*> apis. Valid params include \"search\":\"search\", \"author\":\"author\", \"filter\":\"filter\" and \"sort\":\"sort\".' args_schema=<class 'pydantic.main.get_huggingface_modelsSchemaSchema'> return_direct=False verbose=False callbacks=None callback_manager=None tags=None metadata=None handle_tool_error=<function <lambda> at 0x165c77010> func=<function get_huggingface_models at 0x165ca4700> coroutine=None\n",
      "Got this error: This tool is not implemented yet.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "import requests\n",
    "from langchain.tools.base import StructuredTool, ToolException\n",
    "\n",
    "\n",
    "HF_API_KEY = \"<MY-API-KEY>\"\n",
    "\n",
    "def get_huggingface_models(\n",
    "    path: Optional[str] = None, query_params: Optional[dict] = None):\n",
    "    \"\"\"Tool that calls GET on <https://huggingface.co/models*> apis. Valid params include \"search\":\"search\", \"author\":\"author\", \"filter\":\"filter\" and \"sort\":\"sort\".\"\"\"\n",
    "    raise ToolException(\"This tool is not implemented yet.\")\n",
    "    return {\"result\": \"result\"}\n",
    "\n",
    "\n",
    "\n",
    "get_huggingface_models_tool = StructuredTool.from_function(get_huggingface_models)\n",
    "get_huggingface_models_tool.handle_tool_error = lambda err: print(f\"Got this error: {err}\")\n",
    "print(get_huggingface_models_tool)\n",
    "\n",
    "\n",
    "tool_response = get_huggingface_models_tool.run({\"query_params\": {\"search\": \"gpt-j\"}})\n",
    "print(tool_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_huggingface_models_tool.run({\"query_params\": {\"search\": \"gpt-j\"}})\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Tool Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "import aiohttp\n",
    "import requests\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain.tools import BaseTool\n",
    "from pydantic import BaseModel, BaseSettings, Field\n",
    "\n",
    "class GetHuggingFaceModelsToolSchema(BaseModel):\n",
    "    path: str = Field(default=\"\", description=\"the api path\")\n",
    "    query_params: Optional[dict] = Field(\n",
    "        default=None, description=\"Optional search parameters\"\n",
    "    )\n",
    "\n",
    "class GetHuggingFaceModelsTool(BaseTool, BaseSettings):\n",
    "    \"\"\"My custom tool.\"\"\"\n",
    "\n",
    "    name: str = \"get_huggingface_models\"\n",
    "    description: str = \"\"\"Tool that calls GET on <https://huggingface.co/models*> apis. Valid params include \"search\":\"search\", \"author\":\"author\", \"filter\":\"filter\" and \"sort\":\"sort\".\"\"\"\n",
    "    args_schema: Type[GetHuggingFaceModelsToolSchema] = GetHuggingFaceModelsToolSchema\n",
    "    base_url: str = \"<https://huggingface.co/api/models>\"\n",
    "    api_key: str = Field(..., env=\"HUGGINGFACE_API_KEY\")\n",
    "\n",
    "    @property\n",
    "    def _headers(self) -> dict:\n",
    "        return {\"authorization\": f\"Bearer {self.api_key}\"}\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        path: str = \"\",\n",
    "        query_params: Optional[dict] = None,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> dict:\n",
    "        \"\"\"Run the tool\"\"\"\n",
    "        result = requests.get(\n",
    "            self.base_url + path, params=query_params, headers=self._headers\n",
    "        )\n",
    "        return result.json()\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        path: str = \"\",\n",
    "        query_params: Optional[dict] = None,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> dict:\n",
    "        \"\"\"Run the tool asynchronously.\"\"\"\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(\n",
    "                self.base_url + path, params=query_params, headers=self._headers\n",
    "            ) as response:\n",
    "                return await response.json()\n",
    "\n",
    "get_models_tool = GetHuggingFaceModelsTool()\n",
    "models = get_models_tool.run({\"query_params\": {\"search\": \"gpt-j\"}})\n",
    "print(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
