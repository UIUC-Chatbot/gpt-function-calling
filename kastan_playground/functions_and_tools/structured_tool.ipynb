{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING\"] = \"true\" # If you want to trace the execution of the program, set to \"true\"\n",
    "\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, load_tools\n",
    "\n",
    "from langchain.agents.agent_toolkits import PlayWrightBrowserToolkit\n",
    "from langchain.tools.playwright.utils import (\n",
    "    create_async_playwright_browser,\n",
    "    create_sync_playwright_browser, # A synchronous browser is available, though it isn't compatible with jupyter.\n",
    ")\n",
    "\n",
    "# This import is required only for jupyter notebooks, since they have their own eventloop\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input() -> str:\n",
    "  \"\"\"Placeholder for Slack input from user.\"\"\"\n",
    "  print(\"Insert your text. Enter 'q' or press Ctrl-D (or Ctrl-Z on Windows) to end.\")\n",
    "  contents = []\n",
    "  while True:\n",
    "    try:\n",
    "      line = input()\n",
    "    except EOFError:\n",
    "      break\n",
    "    if line == \"q\":\n",
    "      break\n",
    "    contents.append(line)\n",
    "  return \"\\n\".join(contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEMORY \n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "chat_history = MessagesPlaceholder(variable_name=\"chat_history\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM \n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4-0613\", max_retries=3, request_timeout=60 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOLS\n",
    "async_browser = create_async_playwright_browser()\n",
    "browser_toolkit = PlayWrightBrowserToolkit.from_browser(async_browser=async_browser)\n",
    "tools = browser_toolkit.get_tools()\n",
    "tools\n",
    "\n",
    "human_tools = load_tools(\n",
    "    [\"human\"],\n",
    "    llm=llm,\n",
    "    input_func=get_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ClickTool(name='click_element', description='Click on an element with the given CSS selector', args_schema=<class 'langchain.tools.playwright.click.ClickToolInput'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>, visible_only=True, playwright_strict=False, playwright_timeout=1000),\n",
       " NavigateTool(name='navigate_browser', description='Navigate a browser to the specified URL', args_schema=<class 'langchain.tools.playwright.navigate.NavigateToolInput'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>),\n",
       " NavigateBackTool(name='previous_webpage', description='Navigate back to the previous page in the browser history', args_schema=<class 'pydantic.main.BaseModel'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>),\n",
       " ExtractTextTool(name='extract_text', description='Extract all the text on the current webpage', args_schema=<class 'pydantic.main.BaseModel'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>),\n",
       " ExtractHyperlinksTool(name='extract_hyperlinks', description='Extract all hyperlinks on the current webpage', args_schema=<class 'langchain.tools.playwright.extract_hyperlinks.ExtractHyperlinksToolInput'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>),\n",
       " GetElementsTool(name='get_elements', description='Retrieve elements in the current web page matching the given CSS selector', args_schema=<class 'langchain.tools.playwright.get_elements.GetElementsToolInput'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>),\n",
       " CurrentWebPageTool(name='current_webpage', description='Returns the URL of the current page', args_schema=<class 'pydantic.main.BaseModel'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, sync_browser=None, async_browser=<Browser type=<BrowserType name=chromium executable_path=/Users/kastanday/Library/Caches/ms-playwright/chromium-1055/chrome-mac/Chromium.app/Contents/MacOS/Chromium> version=112.0.5615.29>),\n",
       " HumanInputRun(name='human', description='You can ask a human for guidance when you think you got stuck or you are not sure what to do next. The input should be a question for the human.', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, prompt_func=<function _print_func at 0x1281335b0>, input_func=<function get_input at 0x12f8eb640>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = tools + human_tools\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(\n",
    "  tools, \n",
    "  llm, \n",
    "  agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, \n",
    "  verbose=True,\n",
    "  memory=memory, \n",
    "  agent_kwargs = {\n",
    "    \"memory_prompts\": [chat_history],\n",
    "    \"input_variables\": [\"input\", \"agent_scratchpad\", \"chat_history\"]\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to load default session, using empty session: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sessions?name=default (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x12f9609a0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Before I can browse and summarize the text from the blog, I need to know what the user is interested in learning about on Langchain. I will ask the user for this information.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"human\",\n",
      "  \"action_input\": {\n",
      "    \"query\": \"What specific topics are you interested in learning about on Langchain?\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "What specific topics are you interested in learning about on Langchain?\n",
      "Insert your text. Enter 'q' or press Ctrl-D (or Ctrl-Z on Windows) to end.\n",
      "\n",
      "Observation: \u001b[31;1m\u001b[1;3magents and structured tools\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe user is interested in learning about \"agents\" and \"structured tools\" on Langchain. Now, I will navigate to the Langchain blog to find relevant information.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"navigate_browser\",\n",
      "  \"action_input\": {\n",
      "    \"url\": \"https://blog.langchain.dev\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mNavigating to https://blog.langchain.dev returned status code 200\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that I'm on the Langchain blog, I need to extract the text from the webpage so I can summarize it and find information relevant to \"agents\" and \"structured tools\".\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"extract_text\",\n",
      "  \"action_input\": {}\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mLangChain LangChain Home About GitHub Docs LangChain The official LangChain blog. RealChar x LangSmith: Using Open Source tools to create an AI companion Editor’s Note: This blog post was written in collaboration with RealChar, an early LangSmith BETA user. They moved fast and created something really, really sophisticated and really, really fun to use–all with open source tools.\n",
      "\n",
      "We're also very excited about AI characters and companions internally, which is part Jul 24, 2023 3 min read Featured Announcing LangSmith, a unified platform for debugging, testing, evaluating, and monitoring your LLM applications LangChain exists to make it as easy as possible to develop LLM-powered applications.\n",
      "\n",
      "We started with an open-source Python package when the main blocker for building LLM-powered applications was getting a simple prototype working. We remember seeing Nat Friedman tweet in late 2022 that there was “not enough tinkering happening. Jul 18, 2023 8 min read Code Interpreter API Editor's Note: This is another installation of our guest blog posts highlighting interesting and novel use cases. This blog is written by Shroominic who built an open source implementation of the ChatGPT Code Interpreter.\n",
      "\n",
      "Important Links:\n",
      "\n",
      " * GitHub Repo\n",
      "\n",
      "In the world of open-source software, there are always exciting developments. Today, Jul 16, 2023 5 min read Analyzing User Interactions with LLMs to Improve our Documentation Introduction\n",
      "\n",
      "We're strongly committed to consistently enhancing our documentation and its navigability. Using Mendable, a AI-enabled chat application, users can search our documentation using keywords or questions. Over time, Mendable has collected a large dataset of questions that highlights areas for documentation improvement.\n",
      "\n",
      "\n",
      "Challenge\n",
      "\n",
      "Distilling common themes from tens of Jul 13, 2023 3 min read LangChain x Context: Building Better Chat Products With User Analytics Today we’re announcing a Langchain integration for Context. This integration allows builders of Langchain chat products to receive user analytics with a one line plugin.\n",
      "\n",
      "Building compelling chat products is hard. Developers need a deep understanding of user behaviour and user goals to iteratively improve their products. Common questions Jul 12, 2023 2 min read Neon x LangChain: HNSW in Postgres with pg_embedding Editor’s Note: This blog post was written in collaboration with the Neon team (Raouf Chebri in particular). The vectorstore space is on fire, and we’re excited to highlight new implementations and options. We’re also really excited by the detailed analysis done here, bringing some solid stats and Jul 12, 2023 4 min read LangChain 🤝 Streamlit The initial integration of Streamlit with LangChain and our future plans. Jul 11, 2023 2 min read 🎉 Prem Challenge🎉 We're excited to announce a challenge hosted by Prem in collaboration with LangChain.\n",
      "\n",
      "At LangChain we try to make it easy as possible to experiment with as many different models as possible. That includes the incredible number of emerging open source models. We've made efforts to make our framework as Jun 26, 2023 6 min read LangChain <> MongoDB Atlas Today we’re announcing LangChain’s integration with MongoDB Atlas, adding support for one of the most popular developer data platforms in the world. This is an integration so anticipated that a few developers added the integration before we were ready to announce it :)\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "One of the key components Jun 22, 2023 3 min read Data-Driven Characters Data-driven-characters is a repo for creating, debugging, and interacting your own chatbots conditioned on your own story corpora. Jun 19, 2023 11 min read LangChain + Vectara: better together Introduction\n",
      "\n",
      "One of the main use cases of LangChain is connecting LLMs to user data, allowing users to build personalized LLM applications. A key part of this is retrieval - fetching relevant documents based on user queries.\n",
      "\n",
      "Today we’re happy to announce the integration of Vectara into LangChain to Jun 6, 2023 4 min read GPTeam: A multi-agent simulation Editor's Note: This is another edition in our series of guest posts highlighting novel applications of LangChain. After the Generative Agents paper was released, there was a flurry of open source projects rushing to incorporate some of the key ideas. GPTeam was one of the most impressive ones we saw, Jun 5, 2023 11 min read Going Beyond Chatbots: How to Make GPT-4 Output Structured Data Using LangChain By Jacob Lee\n",
      "\n",
      "Over the past few months, I had the opportunity to do some cool exploratory work for a client that integrated LLMs like GPT-4 and Claude into their internal workflow, rather than exposing them through a chat interface. The general idea was to take some input data, analyze May 21, 2023 4 min read Auto-Evaluation of Anthropic 100k Context Window Lance Martin\n",
      "\n",
      "\n",
      "Retrieval Architectures\n",
      "\n",
      "LLM question answering (Q+A) typically involves retrieval of documents relevant to the question followed by synthesis of the retrieved chunks into an answer by an LLM.  In practice, the retrieval step is necessary because the LLM context window is limited relative to the size of May 16, 2023 3 min read Rebuff: Detecting Prompt Injection Attacks [Editor's Note]: we're excited to highlight a guest blog by Willem Pienaar. As more and more LangChains make their way into production, we're getting an increased amount of questions about the security and privacy of these systems. We did a webinar on this topic a few weeks ago, and the May 14, 2023 4 min read Plan-and-Execute Agents TL;DR: We’re introducing a new type of agent executor, which we’re calling “Plan-and-Execute”. This is to contrast against the previous types of agent we supported, which we’re calling “Action” agents. Plan-and-Execute agents are heavily inspired by BabyAGI and the recent Plan-and-Solve paper. We think Plan-and-Execute is May 10, 2023 4 min read Feature Stores and LLMs Editor's note: big thank you to Willem Pienaar (Feast), Mike Del Balso (Tecton), and Simba Khadder (FeatureForm) for their comments and help on this post.\n",
      "\n",
      "LLMs represent a new paradigm of AI. There is a big open question of how many of the tools and services that were useful for May 9, 2023 5 min read Structured Tools TL;DR: we're introducing a new abstraction to allow for usage of more complex tools. While previous tools took in a single string input, new tools can take in an arbitrary number of inputs of arbitrary types. We are also introducing a new agent class that works well with these May 2, 2023 6 min read Auto-Evaluator Opportunities Editor's Note: this is a guest blog post by Lance Martin.\n",
      "\n",
      "\n",
      "TL;DR\n",
      "\n",
      "We recently open-sourced an auto-evaluator tool for grading LLM question-answer chains. We are now releasing an open source, free to use hosted app and API to expand usability. Below we discuss a few opportunities to further improve May 1, 2023 5 min read Callbacks Improvements TL;DR: We're announcing improvements to our callbacks system, which powers logging, tracing, streaming output, and some awesome third-party integrations. This will better support concurrent runs with independent callbacks, tracing of deeply nested trees of LangChain components, and callback handlers scoped to a single request (which is super useful for May 1, 2023 3 min read Unleashing the power of AI Collaboration with Parallelized LLM Agent Actor Trees Editor's note: the following is a guest blog post from Cyrus at Shaman AI. We use guest blog posts to highlight interesting and novel applciations, and this is certainly that. There's been a lot of talk about agents recently, but most have been discussions around a single agent. If multiple Apr 28, 2023 4 min read Gradio & LLM Agents Editor's note: this is a guest blog post from Freddy Boulton, a software engineer at Gradio. We're excited to share this post because it brings a large number of exciting new tools into the ecosystem. Agents are largely defined by the tools they have, so to be able to equip Apr 23, 2023 4 min read RecAlign - The smart content filter for social media feed [Editor's Note] This is a guest post by Tian Jin. We are highlighting this application as we think it is a novel use case. Specifically, we think recommendation systems are incredibly impactful in our everyday lives and there has not been a ton of discourse on how LLMs will impact Apr 22, 2023 3 min read Improving Document Retrieval with Contextual Compression Note: This post assumes some familiarity with LangChain and is moderately technical.\n",
      "\n",
      "💡 TL;DR: We’ve introduced a new abstraction and a new document Retriever to facilitate the post-processing of retrieved documents. Specifically, the new abstraction makes it easy to take a set of retrieved documents and extract from them Apr 20, 2023 3 min read Autonomous Agents & Agent Simulations Over the past two weeks, there has been a massive increase in using LLMs in an agentic manner. Specifically, projects like AutoGPT, BabyAGI, CAMEL, and Generative Agents have popped up. The LangChain community has now implemented some parts of all of those projects in the LangChain framework. While researching and Apr 18, 2023 7 min read Page 1 of 3 Older Posts → LangChain © 2023 Sign up Powered by Ghost\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe extracted text contains a lot of information about LangChain, including various blog posts and announcements. I need to find the parts of the text that mention \"agents\" and \"structured tools\", as these are the topics the user is interested in. I will search the text for these keywords. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"get_elements\",\n",
      "  \"action_input\": {\n",
      "    \"selector\": \"body\",\n",
      "    \"attributes\": [\"innerText\"]\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m[{\"innerText\": \"Home\\nAbout\\nGitHub\\nDocs\\nLangChain\\n\\nThe official LangChain blog.\\n\\nRealChar x LangSmith: Using Open Source tools to create an AI companion\\nEditor’s Note: This blog post was written in collaboration with RealChar, an early LangSmith BETA user. They moved fast and created something really, really sophisticated and really, really fun to use–all with open source tools. We're also very excited about AI characters and companions internally, which is part\\nJul 24, 2023\\n3 min read\\nFeatured\\nAnnouncing LangSmith, a unified platform for debugging, testing, evaluating, and monitoring your LLM applications\\nLangChain exists to make it as easy as possible to develop LLM-powered applications. We started with an open-source Python package when the main blocker for building LLM-powered applications was getting a simple prototype working. We remember seeing Nat Friedman tweet in late 2022 that there was “not enough tinkering happening.\\nJul 18, 2023\\n8 min read\\nCode Interpreter API\\nEditor's Note: This is another installation of our guest blog posts highlighting interesting and novel use cases. This blog is written by Shroominic who built an open source implementation of the ChatGPT Code Interpreter. Important Links: * GitHub Repo In the world of open-source software, there are always exciting developments. Today,\\nJul 16, 2023\\n5 min read\\nAnalyzing User Interactions with LLMs to Improve our Documentation\\nIntroduction We're strongly committed to consistently enhancing our documentation and its navigability. Using Mendable, a AI-enabled chat application, users can search our documentation using keywords or questions. Over time, Mendable has collected a large dataset of questions that highlights areas for documentation improvement. Challenge Distilling common themes from tens of\\nJul 13, 2023\\n3 min read\\nLangChain x Context: Building Better Chat Products With User Analytics\\nToday we’re announcing a Langchain integration for Context. This integration allows builders of Langchain chat products to receive user analytics with a one line plugin. Building compelling chat products is hard. Developers need a deep understanding of user behaviour and user goals to iteratively improve their products. Common questions\\nJul 12, 2023\\n2 min read\\nNeon x LangChain: HNSW in Postgres with pg_embedding\\nEditor’s Note: This blog post was written in collaboration with the Neon team (Raouf Chebri in particular). The vectorstore space is on fire, and we’re excited to highlight new implementations and options. We’re also really excited by the detailed analysis done here, bringing some solid stats and\\nJul 12, 2023\\n4 min read\\nLangChain 🤝 Streamlit\\nThe initial integration of Streamlit with LangChain and our future plans.\\nJul 11, 2023\\n2 min read\\n🎉 Prem Challenge🎉\\nWe're excited to announce a challenge hosted by Prem in collaboration with LangChain. At LangChain we try to make it easy as possible to experiment with as many different models as possible. That includes the incredible number of emerging open source models. We've made efforts to make our framework as\\nJun 26, 2023\\n6 min read\\nLangChain <> MongoDB Atlas\\nToday we’re announcing LangChain’s integration with MongoDB Atlas, adding support for one of the most popular developer data platforms in the world. This is an integration so anticipated that a few developers added the integration before we were ready to announce it :) Overview One of the key components\\nJun 22, 2023\\n3 min read\\nData-Driven Characters\\nData-driven-characters is a repo for creating, debugging, and interacting your own chatbots conditioned on your own story corpora.\\nJun 19, 2023\\n11 min read\\nLangChain + Vectara: better together\\nIntroduction One of the main use cases of LangChain is connecting LLMs to user data, allowing users to build personalized LLM applications. A key part of this is retrieval - fetching relevant documents based on user queries. Today we’re happy to announce the integration of Vectara into LangChain to\\nJun 6, 2023\\n4 min read\\nGPTeam: A multi-agent simulation\\nEditor's Note: This is another edition in our series of guest posts highlighting novel applications of LangChain. After the Generative Agents paper was released, there was a flurry of open source projects rushing to incorporate some of the key ideas. GPTeam was one of the most impressive ones we saw,\\nJun 5, 2023\\n11 min read\\nGoing Beyond Chatbots: How to Make GPT-4 Output Structured Data Using LangChain\\nBy Jacob Lee Over the past few months, I had the opportunity to do some cool exploratory work for a client that integrated LLMs like GPT-4 and Claude into their internal workflow, rather than exposing them through a chat interface. The general idea was to take some input data, analyze\\nMay 21, 2023\\n4 min read\\nAuto-Evaluation of Anthropic 100k Context Window\\nLance Martin Retrieval Architectures LLM question answering (Q+A) typically involves retrieval of documents relevant to the question followed by synthesis of the retrieved chunks into an answer by an LLM.  In practice, the retrieval step is necessary because the LLM context window is limited relative to the size of\\nMay 16, 2023\\n3 min read\\nRebuff: Detecting Prompt Injection Attacks\\n[Editor's Note]: we're excited to highlight a guest blog by Willem Pienaar. As more and more LangChains make their way into production, we're getting an increased amount of questions about the security and privacy of these systems. We did a webinar on this topic a few weeks ago, and the\\nMay 14, 2023\\n4 min read\\nPlan-and-Execute Agents\\nTL;DR: We’re introducing a new type of agent executor, which we’re calling “Plan-and-Execute”. This is to contrast against the previous types of agent we supported, which we’re calling “Action” agents. Plan-and-Execute agents are heavily inspired by BabyAGI and the recent Plan-and-Solve paper. We think Plan-and-Execute is\\nMay 10, 2023\\n4 min read\\nFeature Stores and LLMs\\nEditor's note: big thank you to Willem Pienaar (Feast), Mike Del Balso (Tecton), and Simba Khadder (FeatureForm) for their comments and help on this post. LLMs represent a new paradigm of AI. There is a big open question of how many of the tools and services that were useful for\\nMay 9, 2023\\n5 min read\\nStructured Tools\\nTL;DR: we're introducing a new abstraction to allow for usage of more complex tools. While previous tools took in a single string input, new tools can take in an arbitrary number of inputs of arbitrary types. We are also introducing a new agent class that works well with these\\nMay 2, 2023\\n6 min read\\nAuto-Evaluator Opportunities\\nEditor's Note: this is a guest blog post by Lance Martin. TL;DR We recently open-sourced an auto-evaluator tool for grading LLM question-answer chains. We are now releasing an open source, free to use hosted app and API to expand usability. Below we discuss a few opportunities to further improve\\nMay 1, 2023\\n5 min read\\nCallbacks Improvements\\nTL;DR: We're announcing improvements to our callbacks system, which powers logging, tracing, streaming output, and some awesome third-party integrations. This will better support concurrent runs with independent callbacks, tracing of deeply nested trees of LangChain components, and callback handlers scoped to a single request (which is super useful for\\nMay 1, 2023\\n3 min read\\nUnleashing the power of AI Collaboration with Parallelized LLM Agent Actor Trees\\nEditor's note: the following is a guest blog post from Cyrus at Shaman AI. We use guest blog posts to highlight interesting and novel applciations, and this is certainly that. There's been a lot of talk about agents recently, but most have been discussions around a single agent. If multiple\\nApr 28, 2023\\n4 min read\\nGradio & LLM Agents\\nEditor's note: this is a guest blog post from Freddy Boulton, a software engineer at Gradio. We're excited to share this post because it brings a large number of exciting new tools into the ecosystem. Agents are largely defined by the tools they have, so to be able to equip\\nApr 23, 2023\\n4 min read\\nRecAlign - The smart content filter for social media feed\\n[Editor's Note] This is a guest post by Tian Jin. We are highlighting this application as we think it is a novel use case. Specifically, we think recommendation systems are incredibly impactful in our everyday lives and there has not been a ton of discourse on how LLMs will impact\\nApr 22, 2023\\n3 min read\\nImproving Document Retrieval with Contextual Compression\\nNote: This post assumes some familiarity with LangChain and is moderately technical. 💡 TL;DR: We’ve introduced a new abstraction and a new document Retriever to facilitate the post-processing of retrieved documents. Specifically, the new abstraction makes it easy to take a set of retrieved documents and extract from them\\nApr 20, 2023\\n3 min read\\nAutonomous Agents & Agent Simulations\\nOver the past two weeks, there has been a massive increase in using LLMs in an agentic manner. Specifically, projects like AutoGPT, BabyAGI, CAMEL, and Generative Agents have popped up. The LangChain community has now implemented some parts of all of those projects in the LangChain framework. While researching and\\nApr 18, 2023\\n7 min read\\nLangChain © 2023\\nSign up\\nPowered by Ghost\"}]\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to persist run: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /chain-runs (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x14835ebf0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe extracted elements contain the full text of the webpage. I can see that there are several mentions of \"agents\" and \"structured tools\" in the text. I will now summarize the relevant parts of the text.\n",
      "\n",
      "The blog post titled \"Plan-and-Execute Agents\" introduces a new type of agent executor called \"Plan-and-Execute\", which contrasts against the previous types of agents, referred to as \"Action\" agents. Plan-and-Execute agents are heavily inspired by BabyAGI and the recent Plan-and-Solve paper.\n",
      "\n",
      "In the post titled \"Structured Tools\", a new abstraction is introduced to allow for the usage of more complex tools. While previous tools took in a single string input, new tools can take in an arbitrary number of inputs of arbitrary types. A new agent class that works well with these structured tools is also introduced.\n",
      "\n",
      "The post \"GPTeam: A multi-agent simulation\" highlights novel applications of LangChain. After the Generative Agents paper was released, there was a rush of open source projects incorporating some of the key ideas. GPTeam was one of the most impressive ones seen, indicating a strong interest in agent-based applications.\n",
      "\n",
      "The post \"Unleashing the power of AI Collaboration with Parallelized LLM Agent Actor Trees\" discusses the potential of multiple agents working in parallel, which is a novel application of LangChain. This suggests that there is a lot of ongoing research and development in the area of agents.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The LangChain blog contains several posts relevant to your interests. The post titled 'Plan-and-Execute Agents' introduces a new type of agent executor called 'Plan-and-Execute', which contrasts against the previous types of agents, referred to as 'Action' agents. In the post titled 'Structured Tools', a new abstraction is introduced to allow for the usage of more complex tools. The post 'GPTeam: A multi-agent simulation' highlights novel applications of LangChain, indicating a strong interest in agent-based applications. The post 'Unleashing the power of AI Collaboration with Parallelized LLM Agent Actor Trees' discusses the potential of multiple agents working in parallel. This suggests that there is a lot of ongoing research and development in the area of agents and structured tools on LangChain.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The LangChain blog contains several posts relevant to your interests. The post titled 'Plan-and-Execute Agents' introduces a new type of agent executor called 'Plan-and-Execute', which contrasts against the previous types of agents, referred to as 'Action' agents. In the post titled 'Structured Tools', a new abstraction is introduced to allow for the usage of more complex tools. The post 'GPTeam: A multi-agent simulation' highlights novel applications of LangChain, indicating a strong interest in agent-based applications. The post 'Unleashing the power of AI Collaboration with Parallelized LLM Agent Actor Trees' discusses the potential of multiple agents working in parallel. This suggests that there is a lot of ongoing research and development in the area of agents and structured tools on LangChain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/sry3qhhx5ls2vpwn1y7_b3p40000gn/T/ipykernel_42313/2953221896.py:3: RuntimeWarning: coroutine 'Chain.arun' was never awaited\n",
      "  response = await agent_chain.arun(input=\"Ask the user what they're interested in learning about on Langchain, then Browse to blog.langchain.dev and summarize the text especially whatever is relevant to the user, please.\")\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# asycn and sync together is tough...\n",
    "\n",
    "response = await agent_chain.arun(input=\"Ask the user what they're interested in learning about on Langchain, then Browse to blog.langchain.dev and summarize the text especially whatever is relevant to the user, please.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The LangChain blog contains several posts relevant to your interests. The post titled 'Plan-and-Execute Agents' introduces a new type of agent executor called 'Plan-and-Execute', which contrasts against the previous types of agents, referred to as 'Action' agents. In the post titled 'Structured Tools', a new abstraction is introduced to allow for the usage of more complex tools. The post 'GPTeam: A multi-agent simulation' highlights novel applications of LangChain, indicating a strong interest in agent-based applications. The post 'Unleashing the power of AI Collaboration with Parallelized LLM Agent Actor Trees' discusses the potential of multiple agents working in parallel. This suggests that there is a lot of ongoing research and development in the area of agents and structured tools on LangChain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent_chain.arun(input=\"Browse to blog.langchain.dev and summarize the text, please.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
